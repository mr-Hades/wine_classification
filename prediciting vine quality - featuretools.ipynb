{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T23:51:44.633089Z",
     "start_time": "2020-06-24T23:51:43.826245Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T23:51:45.573577Z",
     "start_time": "2020-06-24T23:51:44.636081Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T23:51:45.623442Z",
     "start_time": "2020-06-24T23:51:45.576567Z"
    }
   },
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('./winequalityN.csv')\n",
    "df_orig.dropna(inplace=True)\n",
    "# df_white = df[df.type=='white'].drop(columns='type')\n",
    "# df_red = df[df.type=='white'].drop(columns='type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* highly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T23:51:45.630423Z",
     "start_time": "2020-06-24T23:51:45.626433Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T23:51:46.208877Z",
     "start_time": "2020-06-24T23:51:45.643388Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T11:58:09.283696Z",
     "start_time": "2020-06-25T11:58:09.252775Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_orig.copy()\n",
    "df['type'] = df.type.map({'red': 1, 'white': 0})\n",
    "df['quality'] = df['quality'].map({3:0, 4:0, 5:1, 6:2, 7:3, 8:4, 9:4})\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(df.drop(columns=['quality']),\n",
    "                                                             df['quality'],\n",
    "                                                             stratify=df['quality'],\n",
    "                                                             test_size=0.2,\n",
    "                                                             shuffle=True,\n",
    "                                                             random_state=RANDOM_SEED )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T11:58:09.575911Z",
     "start_time": "2020-06-25T11:58:09.572920Z"
    }
   },
   "outputs": [],
   "source": [
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T11:58:19.777645Z",
     "start_time": "2020-06-25T11:58:09.993821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 78 features\n",
      "EntitySet scattered to 12 workers in 5 seconds                                                                         \n",
      "Elapsed: 00:01 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(x_train_val, columns=df_orig.columns[:-1])\n",
    "data['index'] = data.index\n",
    "es = ft.EntitySet(id='asd')\n",
    "es = es.entity_from_dataframe(\n",
    "                              entity_id = 'wines',\n",
    "                              dataframe = data,\n",
    "                              index='index'\n",
    "                             )\n",
    "\n",
    "features_train, feature_names = ft.dfs(\n",
    "                                 entityset=es,\n",
    "                                 target_entity='wines', \n",
    "                                 max_depth = 2,\n",
    "                                 verbose = 1, \n",
    "                                 n_jobs = -1,\n",
    "                                 trans_primitives = ['multiply_numeric'],\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T11:58:28.982045Z",
     "start_time": "2020-06-25T11:58:19.778641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 78 features\n",
      "EntitySet scattered to 12 workers in 5 seconds                                                                         \n",
      "Elapsed: 00:01 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(x_test, columns=df_orig.columns[:-1])\n",
    "data['index'] = data.index\n",
    "es = ft.EntitySet(id='asd')\n",
    "es = es.entity_from_dataframe(\n",
    "                              entity_id = 'wines',\n",
    "                              dataframe = data,\n",
    "                              index='index'\n",
    "                             )\n",
    "\n",
    "features_test, feature_names = ft.dfs(\n",
    "                                 entityset=es,\n",
    "                                 target_entity='wines', \n",
    "                                 max_depth = 2,\n",
    "                                 verbose = 1, \n",
    "                                 n_jobs = -1,\n",
    "                                 trans_primitives = ['multiply_numeric'],\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T23:57:30.666223Z",
     "start_time": "2020-06-24T23:57:30.661236Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:01:22.695064Z",
     "start_time": "2020-06-25T00:01:16.985324Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hades\\Anaconda3\\envs\\torch_cv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eval</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0.548743</td>\n",
       "      <td>0.488808</td>\n",
       "      <td>0.548743</td>\n",
       "      <td>5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0.527456</td>\n",
       "      <td>0.464367</td>\n",
       "      <td>0.527456</td>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Eval       Acc       Rec        F1  Support\n",
       "0  train  0.548743  0.488808  0.548743     5170\n",
       "1   test  0.527456  0.464367  0.527456     1293"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train_val = ss.fit_transform(features_train)\n",
    "x_test = ss.transform(features_test)\n",
    "\n",
    "class_weight = {label:(y_train_val==label).sum()/len(y_train_val) for label in y_train_val.unique()}\n",
    "lr = LogisticRegressionCV(random_state=RANDOM_SEED,  \n",
    "                          n_jobs=-1,\n",
    "                          Cs=3,\n",
    "                          cv = 5,\n",
    "                          max_iter=500,\n",
    "                          class_weight=class_weight,\n",
    "                         )\n",
    "\n",
    "lr.fit(x_train_val, y_train_val)\n",
    "\n",
    "pred_train = lr.predict(x_train_val)\n",
    "acc_train = (y_train_val == pred_train).sum() / len(y_train_val)\n",
    "f1_train = f1_score(y_train_val, pred_train, average='weighted')\n",
    "bal_acc_train = recall_score(y_train_val, pred_train, average='weighted')\n",
    "res.append(['train', acc_train, f1_train, bal_acc_train, len(y_train_val)])\n",
    "\n",
    "pred_test = lr.predict(x_test)\n",
    "acc_test = (y_test == pred_test).sum() / len(y_test)\n",
    "f1_test = f1_score(y_test, pred_test, average='weighted')\n",
    "bal_acc_test = recall_score(y_test, pred_test, average='weighted')\n",
    "res.append(['test', acc_test, f1_test, bal_acc_test, len(y_test)])\n",
    "\n",
    "df_res = pd.DataFrame(res, columns = ['Eval', 'Acc', 'Rec', 'F1', 'Support'])\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:01:22.718003Z",
     "start_time": "2020-06-25T00:01:22.698056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.639394</td>\n",
       "      <td>0.495305</td>\n",
       "      <td>0.558201</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.489926</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prec       Rec        F1  Support\n",
       "0  1.000000  0.061224  0.115385     49.0\n",
       "1  0.639394  0.495305  0.558201    426.0\n",
       "2  0.489926  0.819149  0.613139    564.0\n",
       "3  0.375000  0.027907  0.051948    215.0\n",
       "4  0.000000  0.000000  0.000000     39.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(precision_recall_fscore_support(y_test, pred_test, average=None)).T,\n",
    "             columns = ['Prec', 'Rec', 'F1', 'Support'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:13:39.227046Z",
     "start_time": "2020-06-25T12:13:39.223057Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:16:37.499585Z",
     "start_time": "2020-06-25T12:14:32.363670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eval</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0.855899</td>\n",
       "      <td>0.855232</td>\n",
       "      <td>0.855899</td>\n",
       "      <td>5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0.583913</td>\n",
       "      <td>0.579232</td>\n",
       "      <td>0.583913</td>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Eval       Acc       Rec        F1  Support\n",
       "0  train  0.855899  0.855232  0.855899     5170\n",
       "1   test  0.583913  0.579232  0.583913     1293"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_orig.copy()\n",
    "df['type'] = df.type.map({'red': 1, 'white': 0})\n",
    "df.drop(columns='type', inplace=True)\n",
    "df['quality'] = df['quality'].map({3:0, 4:0, 5:1, 6:2, 7:3, 8:4, 9:4})\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(df.drop(columns=['quality']),\n",
    "                                                            df['quality'],\n",
    "                                                             stratify=df['quality'],\n",
    "                                                             test_size=0.2,\n",
    "                                                             shuffle=True,\n",
    "                                                             random_state=RANDOM_SEED )\n",
    "\n",
    "res = []\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train_val = ss.fit_transform(features_train)\n",
    "x_test = ss.transform(features_test)\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', C=300, cache_size=4000, random_state=RANDOM_SEED)\n",
    "clf.fit(x_train_val, y_train_val)\n",
    "\n",
    "pred_train = clf.predict(x_train_val)\n",
    "acc_train = (y_train_val == pred_train).sum() / len(y_train_val)\n",
    "f1_train = f1_score(y_train_val, pred_train, average='weighted')\n",
    "bal_acc_train = recall_score(y_train_val, pred_train, average='weighted')\n",
    "res.append(['train', acc_train, f1_train, bal_acc_train, len(y_train_val)])\n",
    "\n",
    "pred_test = clf.predict(x_test)\n",
    "acc_test = (y_test == pred_test).sum() / len(y_test)\n",
    "f1_test = f1_score(y_test, pred_test, average='weighted')\n",
    "bal_acc_test = recall_score(y_test, pred_test, average='weighted')\n",
    "res.append(['test', acc_test, f1_test, bal_acc_test, len(y_test)])\n",
    "\n",
    "df_res = pd.DataFrame(res, columns = ['Eval', 'Acc', 'Rec', 'F1', 'Support'])\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:16:37.511604Z",
     "start_time": "2020-06-25T12:16:37.500601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.902375</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891596</td>\n",
       "      <td>0.860165</td>\n",
       "      <td>0.875598</td>\n",
       "      <td>1702.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.817161</td>\n",
       "      <td>0.903369</td>\n",
       "      <td>0.858105</td>\n",
       "      <td>2256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.872603</td>\n",
       "      <td>0.741560</td>\n",
       "      <td>0.801762</td>\n",
       "      <td>859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.827338</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prec       Rec        F1  Support\n",
       "0  0.929348  0.876923  0.902375    195.0\n",
       "1  0.891596  0.860165  0.875598   1702.0\n",
       "2  0.817161  0.903369  0.858105   2256.0\n",
       "3  0.872603  0.741560  0.801762    859.0\n",
       "4  0.958333  0.727848  0.827338    158.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(precision_recall_fscore_support(y_train_val, pred_train, average=None)).T,\n",
    "             columns = ['Prec', 'Rec', 'F1', 'Support'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:16:37.523522Z",
     "start_time": "2020-06-25T12:16:37.512579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.633028</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.640371</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.656028</td>\n",
       "      <td>0.622896</td>\n",
       "      <td>564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.390698</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prec       Rec        F1  Support\n",
       "0  0.230769  0.244898  0.237624     49.0\n",
       "1  0.633028  0.647887  0.640371    426.0\n",
       "2  0.592949  0.656028  0.622896    564.0\n",
       "3  0.535032  0.390698  0.451613    215.0\n",
       "4  0.541667  0.333333  0.412698     39.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(precision_recall_fscore_support(y_test, pred_test, average=None)).T,\n",
    "             columns = ['Prec', 'Rec', 'F1', 'Support'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T11:58:28.997017Z",
     "start_time": "2020-06-25T11:58:28.983047Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "features_train['weight'] = y_train_val.map(y_train_val.value_counts(normalize=True))\n",
    "features_train['weight']\n",
    "light_ds_train = lightgbm.Dataset(features_train, label=y_train_val, weight='weight')\n",
    "features_train.drop(columns='weight', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T11:58:30.247660Z",
     "start_time": "2020-06-25T11:58:30.244670Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T11:58:31.812480Z",
     "start_time": "2020-06-25T11:58:31.807522Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'application': 'multiclass',\n",
    "              'bagging_fraction': 0.75,\n",
    "              'bagging_freq': 3,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.85,\n",
    "              'is_unbalance': 'true',\n",
    "              'lambda_l1': 1,\n",
    "              'lambda_l2': 0.01,\n",
    "              'learning_rate': 0.17,\n",
    "              'max_depth': 8,\n",
    "              'metric': 'multi_error',\n",
    "              'num_class': 5,\n",
    "              'num_leaves': 14,\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T11:58:44.340992Z",
     "start_time": "2020-06-25T11:58:40.144229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eval</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0.998839</td>\n",
       "      <td>0.998839</td>\n",
       "      <td>0.998839</td>\n",
       "      <td>5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0.668213</td>\n",
       "      <td>0.663360</td>\n",
       "      <td>0.668213</td>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Eval       Acc       Rec        F1  Support\n",
       "0  train  0.998839  0.998839  0.998839     5170\n",
       "1   test  0.668213  0.663360  0.668213     1293"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lightgbm.train(parameters,\n",
    "                       light_ds_train,\n",
    "                       num_boost_round=350,\n",
    "#                        early_stopping_rounds=10,\n",
    "                      )\n",
    "\n",
    "res = []\n",
    "pred_train = np.argmax(model.predict(features_train), axis=1)\n",
    "acc_train = (y_train_val == pred_train).sum() / len(y_train_val)\n",
    "f1_train = f1_score(y_train_val, pred_train, average='weighted')\n",
    "bal_acc_train = recall_score(y_train_val, pred_train, average='weighted')\n",
    "res.append(['train', acc_train, f1_train, bal_acc_train, len(y_train_val)])\n",
    "\n",
    "pred_test = np.argmax(model.predict(features_test), axis=1)\n",
    "acc_test = (y_test == pred_test).sum() / len(y_test)\n",
    "f1_test = f1_score(y_test, pred_test, average='weighted')\n",
    "bal_acc_test = recall_score(y_test, pred_test, average='weighted')\n",
    "res.append(['test', acc_test, f1_test, bal_acc_test, len(y_test)])\n",
    "\n",
    "df_res = pd.DataFrame(res, columns = ['Eval', 'Acc', 'Rec', 'F1', 'Support'])\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T11:58:46.668771Z",
     "start_time": "2020-06-25T11:58:46.655836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.712941</td>\n",
       "      <td>0.711268</td>\n",
       "      <td>0.712103</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.647335</td>\n",
       "      <td>0.732270</td>\n",
       "      <td>0.687188</td>\n",
       "      <td>564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.632432</td>\n",
       "      <td>0.544186</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prec       Rec        F1  Support\n",
       "0  0.640000  0.326531  0.432432     49.0\n",
       "1  0.712941  0.711268  0.712103    426.0\n",
       "2  0.647335  0.732270  0.687188    564.0\n",
       "3  0.632432  0.544186  0.585000    215.0\n",
       "4  0.750000  0.384615  0.508475     39.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(precision_recall_fscore_support(y_test, pred_test, average=None)).T,\n",
    "             columns = ['Prec', 'Rec', 'F1', 'Support'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best results so far"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
